{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CovR4kgnqbiN",
    "outputId": "6a9d4459-999e-4f8c-daae-f64e88009bcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (4.10.1)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (from tweepy) (3.2.1)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (from tweepy) (2.27.1)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (1.26.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 601
    },
    "id": "lq0KOxI5sbuG",
    "outputId": "85b95cde-14fe-429d-9a39-a056ea8f413b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (4.10.1)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (from tweepy) (3.2.1)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (from tweepy) (2.27.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wdcNDkogS9kL",
    "outputId": "51be7dfc-177d-4da8-979b-0999f9b5b7ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweet-preprocessor in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (0.6.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install tweet-preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "js5qygystvgz",
    "outputId": "0cb0f1eb-a835-48d2-8d0e-20f8dfb994fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy-langdetect in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (0.1.2)\n",
      "Requirement already satisfied: langdetect==1.0.7 in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (from spacy-langdetect) (1.0.7)\n",
      "Requirement already satisfied: pytest in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (from spacy-langdetect) (7.1.3)\n",
      "Requirement already satisfied: six in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (from langdetect==1.0.7->spacy-langdetect) (1.16.0)\n",
      "Requirement already satisfied: packaging in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (from pytest->spacy-langdetect) (21.3)\n",
      "Requirement already satisfied: py>=1.8.2 in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (from pytest->spacy-langdetect) (1.11.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (from pytest->spacy-langdetect) (21.4.0)\n",
      "Requirement already satisfied: iniconfig in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (from pytest->spacy-langdetect) (1.1.1)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (from pytest->spacy-langdetect) (1.0.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (from pytest->spacy-langdetect) (2.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/priyank/opt/miniconda3/lib/python3.9/site-packages (from packaging->pytest->spacy-langdetect) (3.0.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy-langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tweepy in /Users/priyank/Library/Python/3.8/lib/python/site-packages (4.10.1)\n",
      "Requirement already satisfied: nltk in /Users/priyank/Library/Python/3.8/lib/python/site-packages (3.7)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /Users/priyank/Library/Python/3.8/lib/python/site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in /Users/priyank/Library/Python/3.8/lib/python/site-packages (from tweepy) (3.2.1)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in /Users/priyank/Library/Python/3.8/lib/python/site-packages (from tweepy) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/priyank/Library/Python/3.8/lib/python/site-packages (from requests<3,>=2.27.0->tweepy) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests<3,>=2.27.0->tweepy) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests<3,>=2.27.0->tweepy) (1.26.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests<3,>=2.27.0->tweepy) (2.10)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/priyank/Library/Python/3.8/lib/python/site-packages (from nltk) (2022.9.13)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk) (4.60.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tweepy nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (2.3.5)\n",
      "Requirement already satisfied: spacy_langdetect in /Users/priyank/Library/Python/3.8/lib/python/site-packages (0.1.2)\n",
      "Requirement already satisfied: preprocessor in /Users/priyank/Library/Python/3.8/lib/python/site-packages (1.1.3)\n",
      "Requirement already satisfied: textblob in /Users/priyank/Library/Python/3.8/lib/python/site-packages (0.17.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (49.2.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/priyank/Library/Python/3.8/lib/python/site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (7.4.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (1.20.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (4.60.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/priyank/Library/Python/3.8/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: langdetect==1.0.7 in /Users/priyank/Library/Python/3.8/lib/python/site-packages (from spacy_langdetect) (1.0.7)\n",
      "Requirement already satisfied: pytest in /Users/priyank/Library/Python/3.8/lib/python/site-packages (from spacy_langdetect) (7.1.3)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from langdetect==1.0.7->spacy_langdetect) (1.15.0)\n",
      "Requirement already satisfied: nltk>=3.1 in /Users/priyank/Library/Python/3.8/lib/python/site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/priyank/Library/Python/3.8/lib/python/site-packages (from nltk>=3.1->textblob) (2022.9.13)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk>=3.1->textblob) (1.0.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pytest->spacy_langdetect) (20.3.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /Users/priyank/Library/Python/3.8/lib/python/site-packages (from pytest->spacy_langdetect) (1.0.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /Users/priyank/Library/Python/3.8/lib/python/site-packages (from pytest->spacy_langdetect) (2.0.1)\n",
      "Requirement already satisfied: iniconfig in /Users/priyank/Library/Python/3.8/lib/python/site-packages (from pytest->spacy_langdetect) (1.1.1)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pytest->spacy_langdetect) (20.9)\n",
      "Requirement already satisfied: py>=1.8.2 in /Users/priyank/Library/Python/3.8/lib/python/site-packages (from pytest->spacy_langdetect) (1.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from packaging->pytest->spacy_langdetect) (2.4.7)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy spacy_langdetect preprocessor textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "5vAkJa51qwHi"
   },
   "outputs": [],
   "source": [
    "from tweepy import OAuthHandler\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "from spacy_langdetect import LanguageDetector\n",
    "from nltk.corpus import stopwords\n",
    "import preprocessor as p\n",
    "import tweepy \n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "import regex as re\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from tweepy import Client\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K55fbT-dwhHa",
    "outputId": "806be935-4ac2-46c8-9225-f1c478cd7f8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.10.1\n"
     ]
    }
   ],
   "source": [
    "print(tweepy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "vdcyAUIfrTjM"
   },
   "outputs": [],
   "source": [
    "# Twitter credentials\n",
    "# Obtain them from your twitter developer account\n",
    "api_key = 'o42PuIU4CH8HdLvNpzs1wKhIE'\n",
    "api_secret = '023zLUYe2I9NN8kBBS9IAQctxodg8uDUud7MmXzfWnM9WdbhV4'\n",
    "access_key = '1160569234021163010-ksiNnz2fgu90naPDMJp4SMvaQkdJZG'\n",
    "access_secret = '9S0fospW0QqyJRzBQIE0YZAxeFFU5KR50kN9gvEDgdkvi'\n",
    "bearer_token = 'AAAAAAAAAAAAAAAAAAAAANPyiAEAAAAAocSjwd%2BjGKrTY6ujwCSklIYeneE%3D9NQPTtGL9fx8dpXLSJhTMoWZqm2ElOSvGqjT87E2g5bYTe2e1B'\n",
    "client = tweepy.Client(bearer_token)\n",
    "\n",
    "\n",
    "\n",
    "# api_key=o42PuIU4CH8HdLvNpzs1wKhIE\n",
    "\n",
    "# api_key_secret=023zLUYe2I9NN8kBBS9IAQctxodg8uDUud7MmXzfWnM9WdbhV4\n",
    "\n",
    "# acess_token=1160569234021163010-ksiNnz2fgu90naPDMJp4SMvaQkdJZG\n",
    "\n",
    "# acess_token_secret= 9S0fospW0QqyJRzBQIE0YZAxeFFU5KR50kN9gvEDgdkvi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JgAy33B1dVLP"
   },
   "outputs": [],
   "source": [
    "#response = client.search_recent_tweets(\"elonmusk\")\n",
    "# The method returns a Response object, a named tuple with data, includes,\n",
    "# errors, and meta fields\n",
    "#print(response.meta)\n",
    "\n",
    "# In this case, the data field of the Response returned is a list of Tweet\n",
    "# objects\n",
    "#tweets = response.data\n",
    "\n",
    "# Each Tweet object has default ID and text fields\n",
    "#for tweet in tweets:\n",
    "    #print(tweet.id)\n",
    "    #print(tweet.text)\n",
    "\n",
    "# By default, this endpoint/method returns 10 results\n",
    "# # You can retrieve up to 100 Tweets by specifying max_results\n",
    "# response = client.search_recent_tweets(\"Tweepy\", max_results=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "FLf8a39nF648"
   },
   "outputs": [],
   "source": [
    "# Define a pandas dataframe to store the date:\n",
    "db_tweets = pd.DataFrame(columns = ['tweetID', 'AuthorID', 'lang','created_at', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "pdOwTWv3s5_9"
   },
   "outputs": [],
   "source": [
    "def scraptweets(search_words, db_tweets, no_tweets):\n",
    "    \n",
    "    # Define a for-loop to generate tweets at regular intervals\n",
    "    # We cannot make large API call in one go. Hence, let's try T times\n",
    "                            \n",
    "    start_run = time.time()\n",
    "    \n",
    "    # Collect tweets using the Cursor object\n",
    "    # .Cursor() returns an object that you can iterate or loop over to access the data collected.\n",
    "    # Each item in the iterator has various attributes that you can access to get information about each tweet\n",
    "    tweets = tweepy.Paginator(client.search_recent_tweets, query=search_words, \n",
    "                          tweet_fields=['id', 'created_at', 'author_id'], \n",
    "                          user_fields=['public_metrics', 'location', 'username'],\n",
    "                          max_results=100).flatten(limit=500)\n",
    "    \n",
    "    for tweet in tweets:\n",
    "      # Pull the values\n",
    "      text=tweet.text\n",
    "      author_id = tweet.author_id\n",
    "      tweetID = tweet.id\n",
    "      lang=tweet.lang\n",
    "      created_at=tweet.created_at\n",
    "            \n",
    "      # Add the 11 variables to the empty list - ith_tweet:\n",
    "      ith_tweet = [tweetID, author_id, lang, created_at, text]\n",
    "      # Append to dataframe - db_tweets\n",
    "      try:\n",
    "        db_tweets.loc[len(db_tweets)] = ith_tweet\n",
    "      except Exception as e:\n",
    "        print(e)\n",
    "      # increase counter - noTweets  \n",
    "      no_tweets += 1\n",
    "    \n",
    "    # Run ended:\n",
    "    end_run = time.time()\n",
    "    duration_run = round((end_run-start_run)/60, 2)\n",
    "    \n",
    "    print('no. of tweets scraped for run 1 is {}'.format(no_tweets))\n",
    "    print('time take for 1 run to complete is {} mins'.format(duration_run))\n",
    "    \n",
    "    return no_tweets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KbcktdmzTDtu",
    "outputId": "37fd1155-069c-4123-affd-4047626ef07a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of tweets scraped for run 1 is 500\n",
      "time take for 1 run to complete is 0.08 mins\n",
      "no. of tweets scraped for run 1 is 1000\n",
      "time take for 1 run to complete is 0.07 mins\n",
      "no. of tweets scraped for run 1 is 1500\n",
      "time take for 1 run to complete is 0.07 mins\n",
      "no. of tweets scraped for run 1 is 2000\n",
      "time take for 1 run to complete is 0.07 mins\n",
      "no. of tweets scraped for run 1 is 2500\n",
      "time take for 1 run to complete is 0.07 mins\n",
      "no. of tweets scraped for run 1 is 3000\n",
      "time take for 1 run to complete is 0.07 mins\n",
      "no. of tweets scraped for run 1 is 3500\n",
      "time take for 1 run to complete is 0.08 mins\n",
      "no. of tweets scraped for run 1 is 4000\n",
      "time take for 1 run to complete is 0.08 mins\n",
      "no. of tweets scraped for run 1 is 4500\n",
      "time take for 1 run to complete is 0.08 mins\n",
      "no. of tweets scraped for run 1 is 5000\n",
      "time take for 1 run to complete is 0.07 mins\n",
      "no. of tweets scraped for run 1 is 5500\n",
      "time take for 1 run to complete is 0.07 mins\n",
      "no. of tweets scraped for run 1 is 6000\n",
      "time take for 1 run to complete is 0.12 mins\n",
      "no. of tweets scraped for run 1 is 6500\n",
      "time take for 1 run to complete is 0.11 mins\n",
      "no. of tweets scraped for run 1 is 7000\n",
      "time take for 1 run to complete is 0.08 mins\n",
      "no. of tweets scraped for run 1 is 7500\n",
      "time take for 1 run to complete is 0.08 mins\n",
      "no. of tweets scraped for run 1 is 8000\n",
      "time take for 1 run to complete is 0.08 mins\n",
      "no. of tweets scraped for run 1 is 8500\n",
      "time take for 1 run to complete is 0.08 mins\n",
      "no. of tweets scraped for run 1 is 9000\n",
      "time take for 1 run to complete is 0.07 mins\n",
      "no. of tweets scraped for run 1 is 9500\n",
      "time take for 1 run to complete is 0.08 mins\n",
      "no. of tweets scraped for run 1 is 10000\n",
      "time take for 1 run to complete is 0.08 mins\n",
      "no. of tweets scraped for run 1 is 10500\n",
      "time take for 1 run to complete is 0.07 mins\n",
      "no. of tweets scraped for run 1 is 11000\n",
      "time take for 1 run to complete is 0.08 mins\n",
      "no. of tweets scraped for run 1 is 11500\n",
      "time take for 1 run to complete is 0.09 mins\n",
      "no. of tweets scraped for run 1 is 12000\n",
      "time take for 1 run to complete is 0.1 mins\n",
      "no. of tweets scraped for run 1 is 12500\n",
      "time take for 1 run to complete is 0.1 mins\n",
      "no. of tweets scraped for run 1 is 13000\n",
      "time take for 1 run to complete is 0.08 mins\n",
      "no. of tweets scraped for run 1 is 13500\n",
      "time take for 1 run to complete is 0.09 mins\n",
      "no. of tweets scraped for run 1 is 14000\n",
      "time take for 1 run to complete is 0.08 mins\n",
      "no. of tweets scraped for run 1 is 14500\n",
      "time take for 1 run to complete is 0.08 mins\n",
      "no. of tweets scraped for run 1 is 15000\n",
      "time take for 1 run to complete is 0.08 mins\n",
      "no. of tweets scraped for run 1 is 15500\n",
      "time take for 1 run to complete is 0.08 mins\n",
      "no. of tweets scraped for run 1 is 16000\n",
      "time take for 1 run to complete is 0.11 mins\n",
      "no. of tweets scraped for run 1 is 16500\n",
      "time take for 1 run to complete is 0.1 mins\n",
      "no. of tweets scraped for run 1 is 17000\n",
      "time take for 1 run to complete is 0.08 mins\n",
      "no. of tweets scraped for run 1 is 17500\n",
      "time take for 1 run to complete is 0.15 mins\n",
      "no. of tweets scraped for run 1 is 18000\n",
      "time take for 1 run to complete is 0.09 mins\n",
      "no. of tweets scraped for run 1 is 18500\n",
      "time take for 1 run to complete is 0.1 mins\n",
      "no. of tweets scraped for run 1 is 19000\n",
      "time take for 1 run to complete is 0.09 mins\n",
      "no. of tweets scraped for run 1 is 19500\n",
      "time take for 1 run to complete is 0.09 mins\n",
      "no. of tweets scraped for run 1 is 20000\n",
      "time take for 1 run to complete is 0.09 mins\n",
      "no. of tweets scraped for run 1 is 20500\n",
      "time take for 1 run to complete is 0.09 mins\n",
      "no. of tweets scraped for run 1 is 21000\n",
      "time take for 1 run to complete is 0.09 mins\n",
      "no. of tweets scraped for run 1 is 21500\n",
      "time take for 1 run to complete is 0.08 mins\n",
      "no. of tweets scraped for run 1 is 22000\n",
      "time take for 1 run to complete is 0.1 mins\n",
      "no. of tweets scraped for run 1 is 22500\n",
      "time take for 1 run to complete is 0.18 mins\n",
      "no. of tweets scraped for run 1 is 23000\n",
      "time take for 1 run to complete is 0.09 mins\n",
      "no. of tweets scraped for run 1 is 23500\n",
      "time take for 1 run to complete is 0.1 mins\n",
      "no. of tweets scraped for run 1 is 24000\n",
      "time take for 1 run to complete is 0.09 mins\n",
      "no. of tweets scraped for run 1 is 24500\n",
      "time take for 1 run to complete is 0.09 mins\n",
      "no. of tweets scraped for run 1 is 25000\n",
      "time take for 1 run to complete is 0.1 mins\n",
      "no. of tweets scraped for run 1 is 25500\n",
      "time take for 1 run to complete is 0.1 mins\n",
      "no. of tweets scraped for run 1 is 26000\n",
      "time take for 1 run to complete is 0.1 mins\n",
      "no. of tweets scraped for run 1 is 26500\n",
      "time take for 1 run to complete is 0.1 mins\n",
      "no. of tweets scraped for run 1 is 27000\n",
      "time take for 1 run to complete is 0.1 mins\n",
      "no. of tweets scraped for run 1 is 27500\n",
      "time take for 1 run to complete is 0.09 mins\n",
      "no. of tweets scraped for run 1 is 28000\n",
      "time take for 1 run to complete is 0.1 mins\n",
      "no. of tweets scraped for run 1 is 28500\n",
      "time take for 1 run to complete is 0.1 mins\n",
      "no. of tweets scraped for run 1 is 29000\n",
      "time take for 1 run to complete is 0.09 mins\n",
      "no. of tweets scraped for run 1 is 29500\n",
      "time take for 1 run to complete is 0.1 mins\n",
      "no. of tweets scraped for run 1 is 30000\n",
      "time take for 1 run to complete is 0.11 mins\n",
      "no. of tweets scraped for run 1 is 30500\n",
      "time take for 1 run to complete is 0.15 mins\n",
      "no. of tweets scraped for run 1 is 31000\n",
      "time take for 1 run to complete is 0.12 mins\n",
      "no. of tweets scraped for run 1 is 31500\n",
      "time take for 1 run to complete is 0.13 mins\n",
      "no. of tweets scraped for run 1 is 32000\n",
      "time take for 1 run to complete is 0.14 mins\n",
      "no. of tweets scraped for run 1 is 32500\n",
      "time take for 1 run to complete is 0.14 mins\n",
      "no. of tweets scraped for run 1 is 33000\n",
      "time take for 1 run to complete is 0.11 mins\n",
      "no. of tweets scraped for run 1 is 33500\n",
      "time take for 1 run to complete is 0.11 mins\n",
      "no. of tweets scraped for run 1 is 34000\n",
      "time take for 1 run to complete is 0.12 mins\n",
      "no. of tweets scraped for run 1 is 34500\n",
      "time take for 1 run to complete is 0.13 mins\n",
      "no. of tweets scraped for run 1 is 35000\n",
      "time take for 1 run to complete is 0.13 mins\n",
      "no. of tweets scraped for run 1 is 35500\n",
      "time take for 1 run to complete is 0.13 mins\n",
      "no. of tweets scraped for run 1 is 36000\n",
      "time take for 1 run to complete is 0.12 mins\n",
      "no. of tweets scraped for run 1 is 36500\n",
      "time take for 1 run to complete is 0.11 mins\n",
      "no. of tweets scraped for run 1 is 37000\n",
      "time take for 1 run to complete is 0.11 mins\n",
      "no. of tweets scraped for run 1 is 37500\n",
      "time take for 1 run to complete is 0.12 mins\n",
      "no. of tweets scraped for run 1 is 38000\n",
      "time take for 1 run to complete is 0.13 mins\n",
      "no. of tweets scraped for run 1 is 38500\n",
      "time take for 1 run to complete is 0.16 mins\n",
      "no. of tweets scraped for run 1 is 39000\n",
      "time take for 1 run to complete is 0.13 mins\n"
     ]
    },
    {
     "ename": "TooManyRequests",
     "evalue": "429 Too Many Requests\nToo Many Requests",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTooManyRequests\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-cd748c6f53c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0msearch_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'#Hospitalstay OR #hospitalvisit OR #emergencyroomvisit OR #ERvisit OR #Hospitalexperience OR #patientexperience OR #Health OR #patient OR #trauma OR #surgery OR #critical OR #procedure OR #symptoms OR #pain OR #medicine'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m# Call the function scraptweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mtweets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscraptweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb_tweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;31m#new search word string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-7fd78ca65b34>\u001b[0m in \u001b[0;36mscraptweets\u001b[0;34m(search_words, db_tweets, no_tweets)\u001b[0m\n\u001b[1;32m     14\u001b[0m                           max_results=100).flatten(limit=500)\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m       \u001b[0;31m# Pull the values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tweepy/pagination.py\u001b[0m in \u001b[0;36mflatten\u001b[0;34m(self, limit)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         for response in PaginationIterator(self.method, *self.args,\n\u001b[0m\u001b[1;32m     49\u001b[0m                                            **self.kwargs):\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tweepy/pagination.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pagination_token\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpagination_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprevious_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"previous_token\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tweepy/client.py\u001b[0m in \u001b[0;36msearch_recent_tweets\u001b[0;34m(self, query, user_auth, **params)\u001b[0m\n\u001b[1;32m   1246\u001b[0m         \"\"\"\n\u001b[1;32m   1247\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1248\u001b[0;31m         return self._make_request(\n\u001b[0m\u001b[1;32m   1249\u001b[0m             \u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/2/tweets/search/recent\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m             endpoint_parameters=(\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tweepy/client.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, method, route, params, endpoint_parameters, json, data_type, user_auth)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mrequest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         response = self.request(method, route, params=request_params,\n\u001b[0m\u001b[1;32m    127\u001b[0m                                 json=json, user_auth=user_auth)\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tweepy/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, route, params, json, user_auth)\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_auth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTooManyRequests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTwitterServerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTooManyRequests\u001b[0m: 429 Too Many Requests\nToo Many Requests"
     ]
    }
   ],
   "source": [
    "#tweets filtering criteria search words for patients experiences\n",
    "num_runs=981\n",
    "tweets=0\n",
    "for i in range(num_runs):\n",
    "  search_words = '#Hospitalstay OR #hospitalvisit OR #emergencyroomvisit OR #ERvisit OR #Hospitalexperience OR #patientexperience OR #Health OR #patient OR #trauma OR #surgery OR #critical OR #procedure OR #symptoms OR #pain OR #medicine'\n",
    "  # Call the function scraptweets\n",
    "  tweets=scraptweets(search_words, db_tweets, tweets)\n",
    "\n",
    "  #new search word string\n",
    "  search_words = 'Hospital stay OR hospital visit OR emergencyroom visit OR ER visit OR Hospital experience OR patient,  experience OR Health OR patient OR trauma OR surgery OR critical OR procedure OR symptoms OR pain OR medicine'\n",
    "  # Call the function scraptweets\n",
    "  tweets=scraptweets(search_words, db_tweets, tweets)\n",
    "\n",
    "  #new search word string\n",
    "  search_words = 'Hospital OR clinic OR urgent care OR emergency room OR ED OR Nurse OR doctor OR medical professional OR registered nurse OR dr OR patient rep OR patinet engagement OR Treatment OR treat OR assist OR care OR Surgery OR IV OR blood OR ICU OR NICU OR urgent care OR emergency room OR triage OR ED OR bill OR doctor OR bill OR health insurance OR Monitor OR heal OR recover OR care OR cure OR dying OR dead OR sicker OR sick OR ill OR illness OR condition '\n",
    "  # Call the function scraptweets\n",
    "  tweets=scraptweets(search_words, db_tweets, tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "-fgqQwLuGG5L",
    "outputId": "b7137d7a-ed74-440c-8a4e-29358ed191b3"
   },
   "outputs": [],
   "source": [
    "db_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D7jL5FvsHBJy"
   },
   "outputs": [],
   "source": [
    "unique1= db_tweets['tweetID'].unique()\n",
    "unique2=db_tweets['text'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "URIibp_fR-3K",
    "outputId": "7bf4d2a6-32fc-4e1d-8a71-cd9ae86bb1b2"
   },
   "outputs": [],
   "source": [
    "print(len(unique1), ' ',  len(unique2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KlGEgXzOPMTG"
   },
   "outputs": [],
   "source": [
    "db_tweets.drop_duplicates(subset =\"tweetID\",\n",
    "                     keep = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "s9MzVBw3-x47",
    "outputId": "56552255-a702-4407-e502-8b591de60600"
   },
   "outputs": [],
   "source": [
    "db_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A5TatPIzQGC7"
   },
   "outputs": [],
   "source": [
    "#create a new df to store filtered tweets\n",
    "db_cleanTweets=pd.DataFrame(columns = ['tweetID', 'tweetsORG','cleanTweets','Hashtags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "luLKpxabWtNf"
   },
   "outputs": [],
   "source": [
    "#data cleaning\n",
    "nlp = spacy.load('en')  \n",
    "nlp.add_pipe(LanguageDetector(), name='language_detector', last=True) \n",
    "\n",
    "for index, row in db_tweets.iterrows():\n",
    "  #detect if english\n",
    "  tweet=row['text']\n",
    "  doc = nlp(tweet) \n",
    "  detect_language = doc._.language \n",
    "  #skip if its not english\n",
    "  if detect_language['language']!='en':\n",
    "      continue\n",
    "  #find all hashtags    \n",
    "  hashtag=re.findall(r'#(\\w+)', tweet)\n",
    "  #remove hashtags, URL, emojis, mention, number, etc \n",
    "  clean=p.clean(tweet)\n",
    "  ith_row=[row['tweetID'], tweet, clean, hashtag]\n",
    "  db_cleanTweets.loc[len(db_cleanTweets)] = ith_row  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 693
    },
    "id": "8ecSqvjbBnY-",
    "outputId": "c700fbc9-b0ff-4317-ac44-69a3f36e8b45"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-5b84c855-a590-4976-b374-1cb3d79d491d\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetID</th>\n",
       "      <th>tweetsORG</th>\n",
       "      <th>cleanTweets</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1525079862410625024</td>\n",
       "      <td>RT @LapsiaSnehal: It is always nice when the C...</td>\n",
       "      <td>: It is always nice when the CT and OGD correl...</td>\n",
       "      <td>[FOAMrad, FOAMed, meded, radres, futureradres,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1525079857201352704</td>\n",
       "      <td>mohali: Mohali blast: Babbar Khalsa, gangsters...</td>\n",
       "      <td>mohali: Mohali blast: Babbar Khalsa, gangsters...</td>\n",
       "      <td>[news, worldnews, auto, entertainment, busines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1525079805674274816</td>\n",
       "      <td>Polycystic Kidney Disease Symptoms\\n.\\nhttps:/...</td>\n",
       "      <td>Polycystic Kidney Disease Symptoms..</td>\n",
       "      <td>[symptoms, polycystic, kidney, kidneydisease, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1525086602439057408</td>\n",
       "      <td>@AmoneyResists \"Since Rand Paul (R-Moscow) jus...</td>\n",
       "      <td>\"Since Rand Paul (R-Moscow) just unilaterally ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1525086602195787776</td>\n",
       "      <td>RT @freethought202: Gareth, aged 40, is the fi...</td>\n",
       "      <td>: Gareth, aged , is the first Australian to re...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63234</th>\n",
       "      <td>1525131356480581632</td>\n",
       "      <td>RT @redjaspershopp: Just ONE day away! \\nStop ...</td>\n",
       "      <td>: Just ONE day away! Stop by to support awaren...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63235</th>\n",
       "      <td>1525131355138494466</td>\n",
       "      <td>RT @GordonBrown: Tragically, we are sleepwalki...</td>\n",
       "      <td>: Tragically, we are sleepwalking into the nex...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63236</th>\n",
       "      <td>1525131354853154816</td>\n",
       "      <td>RT @ujjainumc: @ujjainumc jas made Green Net c...</td>\n",
       "      <td>: jas made Green Net covering compulsory for u...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63237</th>\n",
       "      <td>1525131354815479808</td>\n",
       "      <td>@RockstarGames @GTASeries @_HEALTH_ so you ack...</td>\n",
       "      <td>so you acknowledged max payne 's year annivers...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63238</th>\n",
       "      <td>1525131354664488962</td>\n",
       "      <td>RT @erdocAA: Nothing I ever learned in medical...</td>\n",
       "      <td>: Nothing I ever learned in medical school sai...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63239 rows Ã— 4 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b84c855-a590-4976-b374-1cb3d79d491d')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-5b84c855-a590-4976-b374-1cb3d79d491d button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-5b84c855-a590-4976-b374-1cb3d79d491d');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                   tweetID                                          tweetsORG  \\\n",
       "0      1525079862410625024  RT @LapsiaSnehal: It is always nice when the C...   \n",
       "1      1525079857201352704  mohali: Mohali blast: Babbar Khalsa, gangsters...   \n",
       "2      1525079805674274816  Polycystic Kidney Disease Symptoms\\n.\\nhttps:/...   \n",
       "3      1525086602439057408  @AmoneyResists \"Since Rand Paul (R-Moscow) jus...   \n",
       "4      1525086602195787776  RT @freethought202: Gareth, aged 40, is the fi...   \n",
       "...                    ...                                                ...   \n",
       "63234  1525131356480581632  RT @redjaspershopp: Just ONE day away! \\nStop ...   \n",
       "63235  1525131355138494466  RT @GordonBrown: Tragically, we are sleepwalki...   \n",
       "63236  1525131354853154816  RT @ujjainumc: @ujjainumc jas made Green Net c...   \n",
       "63237  1525131354815479808  @RockstarGames @GTASeries @_HEALTH_ so you ack...   \n",
       "63238  1525131354664488962  RT @erdocAA: Nothing I ever learned in medical...   \n",
       "\n",
       "                                             cleanTweets  \\\n",
       "0      : It is always nice when the CT and OGD correl...   \n",
       "1      mohali: Mohali blast: Babbar Khalsa, gangsters...   \n",
       "2                   Polycystic Kidney Disease Symptoms..   \n",
       "3      \"Since Rand Paul (R-Moscow) just unilaterally ...   \n",
       "4      : Gareth, aged , is the first Australian to re...   \n",
       "...                                                  ...   \n",
       "63234  : Just ONE day away! Stop by to support awaren...   \n",
       "63235  : Tragically, we are sleepwalking into the nex...   \n",
       "63236  : jas made Green Net covering compulsory for u...   \n",
       "63237  so you acknowledged max payne 's year annivers...   \n",
       "63238  : Nothing I ever learned in medical school sai...   \n",
       "\n",
       "                                                Hashtags  \n",
       "0      [FOAMrad, FOAMed, meded, radres, futureradres,...  \n",
       "1      [news, worldnews, auto, entertainment, busines...  \n",
       "2      [symptoms, polycystic, kidney, kidneydisease, ...  \n",
       "3                                                     []  \n",
       "4                                                     []  \n",
       "...                                                  ...  \n",
       "63234                                                 []  \n",
       "63235                                                 []  \n",
       "63236                                                 []  \n",
       "63237                                                 []  \n",
       "63238                                                 []  \n",
       "\n",
       "[63239 rows x 4 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_cleanTweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fyTUlSpGPcnW"
   },
   "outputs": [],
   "source": [
    "filename='/content/data/cleaned_tweets.csv'\n",
    "db_cleanTweets.to_csv(filename, index = False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Tweets_Extraction&Cleaning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
